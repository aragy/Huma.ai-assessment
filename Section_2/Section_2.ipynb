{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DenseRetriever' from 'langchain.retrievers' (/home/aragy/Huma.ai-assessment/.venv/lib/python3.10/site-packages/langchain/retrievers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastEmbedEmbeddings\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastembed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextEmbedding\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseRetriever\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DenseRetriever' from 'langchain.retrievers' (/home/aragy/Huma.ai-assessment/.venv/lib/python3.10/site-packages/langchain/retrievers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "from langchain.embeddings import FastEmbedEmbeddings\n",
    "from fastembed import TextEmbedding\n",
    "from langchain.retrievers import DenseRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year',\n",
       "  'size_in_GB': 0.42,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.21,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   'hf': 'qdrant/bge-base-en-v1.5-onnx-q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 1.2,\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.067,\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year',\n",
       "  'size_in_GB': 0.22,\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q'},\n",
       "  'model_file': 'model_optimized.onnx'},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 1.2,\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.64,\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.43,\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.54,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 1.02,\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'dim': 1024,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 2.24,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   'hf': 'qdrant/multilingual-e5-large-onnx'},\n",
       "  'model_file': 'model.onnx',\n",
       "  'additional_files': ['model.onnx_data']},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 1.0,\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 0.25,\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'dim': 384,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'size_in_GB': 0.09,\n",
       "  'sources': {'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   'hf': 'qdrant/all-MiniLM-L6-v2-onnx'},\n",
       "  'model_file': 'model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'dim': 512,\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year',\n",
       "  'size_in_GB': 0.12,\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'size_in_GB': 0.32,\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de'},\n",
       "  'model_file': 'onnx/model_fp16.onnx'},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'size_in_GB': 0.64,\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5'},\n",
       "  'model_file': 'onnx/model.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.13,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5'},\n",
       "  'model_file': 'onnx/model_quantized.onnx'},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'dim': 768,\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year',\n",
       "  'size_in_GB': 0.52,\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1'},\n",
       "  'model_file': 'onnx/model.onnx'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/aragy/Huma.ai-assessment/Dataset/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import FastEmbedEmbeddings\n",
    "\n",
    "\n",
    "# class FastEmbedEmbeddingsSingleton:\n",
    "#     _instance = None\n",
    "\n",
    "#     def __new__(cls, *args, **kwargs):\n",
    "#         if cls._instance is None:\n",
    "#             cls._instance = super(FastEmbedEmbeddingsSingleton, cls).__new__(cls)\n",
    "#             cls._instance._init_once(*args, **kwargs)\n",
    "#         return cls._instance\n",
    "\n",
    "#     def _init_once(self, *args, **kwargs):\n",
    "\n",
    "#         self.embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 53092.46it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_model  = FastEmbedEmbeddings(model_name=\"nomic-ai/nomic-embed-text-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_chunks(chunks: list[str]):\n",
    "#     embeddings = fastembed\n",
    "#     db = FAISS.from_texts(chunks, embeddings)\n",
    "#     db.save_local('/home/aragy/Huma.ai-assessment/FAISSDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_similar_chunks(query: str, k: int = 5):\n",
    "#     embeddings = fastembed\n",
    "#     db = FAISS.load_local('/home/aragy/Huma.ai-assessment/FAISSDB', embeddings,allow_dangerous_deserialization=True)\n",
    "#     results = db.similarity_search(query, k)\n",
    "#     return [result.page_content for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>requester_type</th>\n",
       "      <th>product</th>\n",
       "      <th>indication</th>\n",
       "      <th>question</th>\n",
       "      <th>channel</th>\n",
       "      <th>date_time_open</th>\n",
       "      <th>date_time_closed</th>\n",
       "      <th>answer_solution</th>\n",
       "      <th>response_time_hours</th>\n",
       "      <th>question_token_count</th>\n",
       "      <th>answer_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>HCP</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>What are the common side effects of Keytruda?</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-06-27 17:00:00</td>\n",
       "      <td>2023-07-21 18:00:00</td>\n",
       "      <td>Common side effects include fatigue, nausea, a...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Can Keytruda cause immune-related adverse effe...</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-06-08 08:00:00</td>\n",
       "      <td>2023-07-06 12:30:00</td>\n",
       "      <td>Yes, Keytruda can cause immune-related adverse...</td>\n",
       "      <td>676.5</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UK</td>\n",
       "      <td>HCP</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Is Keytruda safe for pregnant women?</td>\n",
       "      <td>call</td>\n",
       "      <td>2023-03-06 04:00:00</td>\n",
       "      <td>2023-04-19 15:00:00</td>\n",
       "      <td>Keytruda is not recommended for use during pre...</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>UK</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>What should patients report immediately while ...</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-02-05 10:30:00</td>\n",
       "      <td>2023-03-05 06:00:00</td>\n",
       "      <td>Patients should report any new or worsening sy...</td>\n",
       "      <td>667.5</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Are there any known interactions between Keytr...</td>\n",
       "      <td>call</td>\n",
       "      <td>2023-03-14 09:30:00</td>\n",
       "      <td>2023-04-16 18:30:00</td>\n",
       "      <td>Yes, Keytruda can interact with steroids and c...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country requester_type   product indication  \\\n",
       "0           0      UK            HCP  Keytruda      NSCLC   \n",
       "1           1      US     Researcher  Keytruda      NSCLC   \n",
       "2           2      UK            HCP  Keytruda      NSCLC   \n",
       "3           3      UK     Researcher  Keytruda      NSCLC   \n",
       "4           4      US     Researcher  Keytruda      NSCLC   \n",
       "\n",
       "                                            question channel  \\\n",
       "0      What are the common side effects of Keytruda?   email   \n",
       "1  Can Keytruda cause immune-related adverse effe...   email   \n",
       "2               Is Keytruda safe for pregnant women?    call   \n",
       "3  What should patients report immediately while ...   email   \n",
       "4  Are there any known interactions between Keytr...    call   \n",
       "\n",
       "        date_time_open     date_time_closed  \\\n",
       "0  2023-06-27 17:00:00  2023-07-21 18:00:00   \n",
       "1  2023-06-08 08:00:00  2023-07-06 12:30:00   \n",
       "2  2023-03-06 04:00:00  2023-04-19 15:00:00   \n",
       "3  2023-02-05 10:30:00  2023-03-05 06:00:00   \n",
       "4  2023-03-14 09:30:00  2023-04-16 18:30:00   \n",
       "\n",
       "                                     answer_solution  response_time_hours  \\\n",
       "0  Common side effects include fatigue, nausea, a...                577.0   \n",
       "1  Yes, Keytruda can cause immune-related adverse...                676.5   \n",
       "2  Keytruda is not recommended for use during pre...               1067.0   \n",
       "3  Patients should report any new or worsening sy...                667.5   \n",
       "4  Yes, Keytruda can interact with steroids and c...                801.0   \n",
       "\n",
       "   question_token_count  answer_token_count  \n",
       "0                     9                  12  \n",
       "1                     7                  17  \n",
       "2                     7                  16  \n",
       "3                    10                  21  \n",
       "4                    11                  18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [row['question']+' '+row['answer_solution'] for _,row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = DenseRetriever(\n",
    "    embeddings=embedding_model,\n",
    "    documents=documents,\n",
    "    index_type=\"faiss\",  # Usando FAISS para recuperação eficiente\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstore_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mstore_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore_chunks\u001b[39m(chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m fastembed\n\u001b[0;32m----> 3\u001b[0m     db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     db\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/aragy/Huma.ai-assessment/FAISSDB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Huma.ai-assessment/.venv/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1041\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m   1043\u001b[0m         texts,\n\u001b[1;32m   1044\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1049\u001b[0m     )\n",
      "File \u001b[0;32m~/Huma.ai-assessment/.venv/lib/python3.10/site-packages/langchain_community/embeddings/fastembed.py:117\u001b[0m, in \u001b[0;36mFastEmbedEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    113\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mpassage_embed(\n\u001b[1;32m    114\u001b[0m         texts, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m(\n\u001b[1;32m    118\u001b[0m         texts, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'embed'"
     ]
    }
   ],
   "source": [
    "store_chunks(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in the index: 49\n"
     ]
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddingsSingleton().embeddings\n",
    "db = FAISS.load_local('./FAISSDB', embeddings,allow_dangerous_deserialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from typing import List\n",
    "#from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain_openai) (0.3.1)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
      "  Downloading openai-1.46.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (0.1.122)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: sniffio in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aragy/HumaAI/Huma.ai-assessment/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "Downloading openai-1.46.0-py3-none-any.whl (375 kB)\n",
      "Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 jiter-0.5.0 langchain_openai-0.2.0 openai-1.46.0 regex-2024.9.11 tiktoken-0.7.0 tqdm-4.66.5\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/home/aragy/Huma.ai-assessment/Dataset/cleaned_dataset.csv')\n",
    "df = pd.read_csv('/home/aragy/HumaAI/Huma.ai-assessment/Dataset/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import FastEmbedEmbeddings\n",
    "\n",
    "\n",
    "# class FastEmbedEmbeddingsSingleton:\n",
    "#     _instance = None\n",
    "\n",
    "#     def __new__(cls, *args, **kwargs):\n",
    "#         if cls._instance is None:\n",
    "#             cls._instance = super(FastEmbedEmbeddingsSingleton, cls).__new__(cls)\n",
    "#             cls._instance._init_once(*args, **kwargs)\n",
    "#         return cls._instance\n",
    "\n",
    "#     def _init_once(self, *args, **kwargs):\n",
    "\n",
    "#         self.embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 53092.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# embedding_model  = FastEmbedEmbeddings(model_name=\"nomic-ai/nomic-embed-text-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_chunks(chunks: list[str]):\n",
    "#     embeddings = fastembed\n",
    "#     db = FAISS.from_texts(chunks, embeddings)\n",
    "#     db.save_local('/home/aragy/Huma.ai-assessment/FAISSDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_similar_chunks(query: str, k: int = 5):\n",
    "#     embeddings = fastembed\n",
    "#     db = FAISS.load_local('/home/aragy/Huma.ai-assessment/FAISSDB', embeddings,allow_dangerous_deserialization=True)\n",
    "#     results = db.similarity_search(query, k)\n",
    "#     return [result.page_content for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>requester_type</th>\n",
       "      <th>product</th>\n",
       "      <th>indication</th>\n",
       "      <th>question</th>\n",
       "      <th>channel</th>\n",
       "      <th>date_time_open</th>\n",
       "      <th>date_time_closed</th>\n",
       "      <th>answer_solution</th>\n",
       "      <th>response_time_hours</th>\n",
       "      <th>question_token_count</th>\n",
       "      <th>answer_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>HCP</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>What are the common side effects of Keytruda?</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-06-27 17:00:00</td>\n",
       "      <td>2023-07-21 18:00:00</td>\n",
       "      <td>Common side effects include fatigue, nausea, a...</td>\n",
       "      <td>577.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Can Keytruda cause immune-related adverse effe...</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-06-08 08:00:00</td>\n",
       "      <td>2023-07-06 12:30:00</td>\n",
       "      <td>Yes, Keytruda can cause immune-related adverse...</td>\n",
       "      <td>676.5</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UK</td>\n",
       "      <td>HCP</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Is Keytruda safe for pregnant women?</td>\n",
       "      <td>call</td>\n",
       "      <td>2023-03-06 04:00:00</td>\n",
       "      <td>2023-04-19 15:00:00</td>\n",
       "      <td>Keytruda is not recommended for use during pre...</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>UK</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>What should patients report immediately while ...</td>\n",
       "      <td>email</td>\n",
       "      <td>2023-02-05 10:30:00</td>\n",
       "      <td>2023-03-05 06:00:00</td>\n",
       "      <td>Patients should report any new or worsening sy...</td>\n",
       "      <td>667.5</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>Keytruda</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>Are there any known interactions between Keytr...</td>\n",
       "      <td>call</td>\n",
       "      <td>2023-03-14 09:30:00</td>\n",
       "      <td>2023-04-16 18:30:00</td>\n",
       "      <td>Yes, Keytruda can interact with steroids and c...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country requester_type   product indication  \\\n",
       "0           0      UK            HCP  Keytruda      NSCLC   \n",
       "1           1      US     Researcher  Keytruda      NSCLC   \n",
       "2           2      UK            HCP  Keytruda      NSCLC   \n",
       "3           3      UK     Researcher  Keytruda      NSCLC   \n",
       "4           4      US     Researcher  Keytruda      NSCLC   \n",
       "\n",
       "                                            question channel  \\\n",
       "0      What are the common side effects of Keytruda?   email   \n",
       "1  Can Keytruda cause immune-related adverse effe...   email   \n",
       "2               Is Keytruda safe for pregnant women?    call   \n",
       "3  What should patients report immediately while ...   email   \n",
       "4  Are there any known interactions between Keytr...    call   \n",
       "\n",
       "        date_time_open     date_time_closed  \\\n",
       "0  2023-06-27 17:00:00  2023-07-21 18:00:00   \n",
       "1  2023-06-08 08:00:00  2023-07-06 12:30:00   \n",
       "2  2023-03-06 04:00:00  2023-04-19 15:00:00   \n",
       "3  2023-02-05 10:30:00  2023-03-05 06:00:00   \n",
       "4  2023-03-14 09:30:00  2023-04-16 18:30:00   \n",
       "\n",
       "                                     answer_solution  response_time_hours  \\\n",
       "0  Common side effects include fatigue, nausea, a...                577.0   \n",
       "1  Yes, Keytruda can cause immune-related adverse...                676.5   \n",
       "2  Keytruda is not recommended for use during pre...               1067.0   \n",
       "3  Patients should report any new or worsening sy...                667.5   \n",
       "4  Yes, Keytruda can interact with steroids and c...                801.0   \n",
       "\n",
       "   question_token_count  answer_token_count  \n",
       "0                     9                  12  \n",
       "1                     7                  17  \n",
       "2                     7                  16  \n",
       "3                    10                  21  \n",
       "4                    11                  18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [row['question']+' '+row['answer_solution'] for _,row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    documents, metadatas=[{\"source\": 1}] * len(documents)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever.k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]  = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    documents, embedding, metadatas=[{\"source\": 2}] * len(documents)\n",
    ")\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 1}, page_content='What are the common side effects of Keytruda? Common side effects include fatigue, nausea, and skin rash.'),\n",
       " Document(metadata={'source': 1}, page_content='Can Keytruda cause immune-related adverse effects? Yes, Keytruda can cause immune-related adverse effects such as colitis, hepatitis, and pneumonitis.'),\n",
       " Document(metadata={'source': 1}, page_content='What were the side effects noted in the KEYNOTE-006 trial? Common side effects included fatigue, itching, and diarrhea.'),\n",
       " Document(metadata={'source': 2}, page_content='Are there specific side effects of Keytruda that NSCLC patients should monitor? NSCLC patients should monitor for cough, shortness of breath, and chest pain, as these could indicate immune-related pneumonitis.'),\n",
       " Document(metadata={'source': 2}, page_content='What should patients report immediately while on Keytruda treatment? Patients should report any new or worsening symptoms such as cough, chest pain, or changes in vision immediately.'),\n",
       " Document(metadata={'source': 1}, page_content=\"How does Keytruda's effectiveness in NSCLC compare between smokers and non-smokers in KEYNOTE-051? The effectiveness was slightly higher in non-smokers, although significant benefits were still observed in smokers.\"),\n",
       " Document(metadata={'source': 1}, page_content='What was the impact of Keytruda on quality of life for NSCLC patients in KEYNOTE-123? Keytruda improved the quality of life by reducing symptoms related to NSCLC and decreasing the side effects typically associated with chemotherapy.'),\n",
       " Document(metadata={'source': 2}, page_content='How do healthcare providers educate patients about the benefits and risks of Keytruda? Healthcare providers offer educational materials, detailed consultations, and regular follow-up to discuss treatment progress and side effects.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever.invoke(\"What are the Keytruda's side effects?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(documents: List[Document]) -> BM25Okapi:\n",
    "    \"\"\"\n",
    "    Create a BM25 index from the given documents.\n",
    "\n",
    "    BM25 (Best Matching 25) is a ranking function used in information retrieval.\n",
    "    It's based on the probabilistic retrieval framework and is an improvement over TF-IDF.\n",
    "\n",
    "    Args:\n",
    "    documents (List[Document]): List of documents to index.\n",
    "\n",
    "    Returns:\n",
    "    BM25Okapi: An index that can be used for BM25 scoring.\n",
    "    \"\"\"\n",
    "    # Tokenize each document by splitting on whitespace\n",
    "    # This is a simple approach and could be improved with more sophisticated tokenization\n",
    "    tokenized_docs = [doc.split() for doc in documents]\n",
    "    return BM25Okapi(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts(documents, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = create_bm25_index(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
    "\n",
    "    Args:\n",
    "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
    "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
    "    query (str): The query string.\n",
    "    k (int): The number of documents to retrieve.\n",
    "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: The top k documents based on the combined scores.\n",
    "    \"\"\"\n",
    "    # Step 1: Get all documents from the vectorstore\n",
    "    all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
    "\n",
    "    # Step 2: Perform BM25 search\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    # Step 3: Perform vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))\n",
    "    \n",
    "    # Step 4: Normalize scores\n",
    "    vector_scores = np.array([score for _, score in vector_results])\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores))\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "\n",
    "    # Step 5: Combine scores\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores  \n",
    "\n",
    "    # Step 6: Rank documents\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "    \n",
    "    # Step 7: Return top k documents\n",
    "    return [all_docs[i] for i in sorted_indices[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the side effects noted in the KEYNOTE-006 trial? Common side effects included fatigue, itching, and diarrhea.',\n",
       " 'What are the financial support options for NSCLC patients needing Keytruda treatment? Financial support options include manufacturer assistance programs, insurance coverage support, and non-profit grants that help with the cost of treatment.',\n",
       " 'How do healthcare providers educate patients about the benefits and risks of Keytruda? Healthcare providers offer educational materials, detailed consultations, and regular follow-up to discuss treatment progress and side effects.',\n",
       " 'How did Keytruda compare to targeted therapies in NSCLC patients with specific genetic alterations in KEYNOTE-006? Keytruda showed comparable efficacy to targeted therapies in patients without specific actionable genetic alterations.',\n",
       " 'Did the KEYNOTE-10086 trial meet its primary endpoints? No detailed information aviable on the given topic.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the Keytruda's side effects?\"\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.5)\n",
    "docs_content = [doc.page_content for doc in top_docs]\n",
    "docs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic  import BaseModel, Field\n",
    "from typing import Deque, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalEvaluatorInput(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_evaluator(query: str, document: str) -> float:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(RetrievalEvaluatorInput)\n",
    "    input_variables = {\"query\": query, \"document\": document}\n",
    "    result = chain.invoke(input_variables).relevance_score\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeRefinementInput(BaseModel):\n",
    "    key_points: str = Field(..., description=\"The document to extract key information from.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_refinement(document: str) -> List[str]:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"document\"],\n",
    "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(KnowledgeRefinementInput)\n",
    "    input_variables = {\"document\": document}\n",
    "    result = chain.invoke(input_variables).key_points\n",
    "    return [point.strip() for point in result.split('\\n') if point.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryRewriterInput(BaseModel):\n",
    "    query: str = Field(..., description=\"The query to rewrite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(query: str) -> str:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(QueryRewriterInput)\n",
    "    input_variables = {\"query\": query}\n",
    "    return chain.invoke(input_variables).query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse a JSON string of search results into a list of title-link tuples.\n",
    "\n",
    "    Args:\n",
    "        results_string (str): A JSON-formatted string containing search results.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
    "                               If parsing fails, an empty list is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to parse the JSON string\n",
    "        results = json.loads(results_string)\n",
    "        # Extract and return the title and link from each result\n",
    "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle JSON decoding errors by returning an empty list\n",
    "        print(\"Error parsing search results. Returning empty list.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on a query using a FAISS index.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
    "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of the retrieved document contents.\n",
    "    \"\"\"\n",
    "    docs = faiss_index.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Evaluate the relevance of documents based on a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        documents (List[str]): A list of document contents to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: A list of relevance scores for each document.\n",
    "    \"\"\"\n",
    "    return [retrieval_evaluator(query, doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Perform a web search based on a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[Tuple[str, str]]]: \n",
    "            - A list of refined knowledge obtained from the web search.\n",
    "            - A list of tuples containing titles and links of the sources.\n",
    "    \"\"\"\n",
    "    rewritten_query = rewrite_query(query)\n",
    "    web_results = search.run(rewritten_query)\n",
    "    web_knowledge = knowledge_refinement(web_results)\n",
    "    sources = parse_search_results(web_results)\n",
    "    return web_knowledge, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response to a query using knowledge and sources.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        knowledge (str): The refined knowledge to use in the response.\n",
    "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    response_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
    "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
    "    )\n",
    "    input_variables = {\n",
    "        \"query\": query,\n",
    "        \"knowledge\": knowledge,\n",
    "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
    "    }\n",
    "    response_chain = response_prompt | llm\n",
    "    return response_chain.invoke(input_variables).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
    "    \"\"\"\n",
    "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to process.\n",
    "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response based on the query.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing query: {query}\")\n",
    "\n",
    "    # Retrieve and evaluate documents\n",
    "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
    "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
    "    print(f\"Evaluation scores: {eval_scores}\")\n",
    "\n",
    "    # Determine action based on evaluation scores\n",
    "    max_score = max(eval_scores)\n",
    "    sources = []\n",
    "    \n",
    "    if max_score > 0.7:\n",
    "        print(\"\\nAction: Correct - Using retrieved document\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        final_knowledge = best_doc\n",
    "        sources.append((\"Retrieved document\", \"\"))\n",
    "    elif max_score < 0.3:\n",
    "        print(\"\\nAction: Incorrect - Performing web search\")\n",
    "        final_knowledge, sources = perform_web_search(query)\n",
    "    else:\n",
    "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        # Refine the retrieved knowledge\n",
    "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
    "        web_knowledge, web_sources = perform_web_search(query)\n",
    "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
    "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
    "\n",
    "    print(\"\\nFinal knowledge:\")\n",
    "    print(final_knowledge)\n",
    "    \n",
    "    print(\"\\nSources:\")\n",
    "    for title, link in sources:\n",
    "        print(f\"{title}: {link}\" if link else title)\n",
    "\n",
    "    # Generate response\n",
    "    print(\"\\nGenerating response...\")\n",
    "    response = generate_response(query, final_knowledge, sources)\n",
    "\n",
    "    print(\"\\nResponse generated\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing query: What are the Keytruda's side effects?\n",
      "\n",
      "Retrieved 3 documents\n",
      "Evaluation scores: [0.9, 0.7, 0.3]\n",
      "\n",
      "Action: Correct - Using retrieved document\n",
      "\n",
      "Final knowledge:\n",
      "What are the common side effects of Keytruda? Common side effects include fatigue, nausea, and skin rash.\n",
      "\n",
      "Sources:\n",
      "Retrieved document\n",
      "\n",
      "Generating response...\n",
      "\n",
      "Response generated\n",
      "Query: What are the Keytruda's side effects?\n",
      "Answer: Keytruda (pembrolizumab) is an immunotherapy drug used to treat various types of cancer. Common side effects associated with Keytruda include:\n",
      "\n",
      "- Fatigue\n",
      "- Nausea\n",
      "- Skin rash\n",
      "\n",
      "These side effects can vary in intensity and may not occur in every patient. It's important for patients to discuss any side effects they experience with their healthcare provider.\n",
      "\n",
      "Sources: Retrieved document.\n"
     ]
    }
   ],
   "source": [
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
